![Unity](https://img.shields.io/badge/Unity-unity?logo=Unity&color=%23000000)
&nbsp;

![License](https://img.shields.io/github/license/HardCodeDev777/UnityNeuroSpeech?color=%2305991d)
![Last commit](https://img.shields.io/github/last-commit/HardCodeDev777/UnityNeuroSpeech?color=%2305991d)
![Tag](https://img.shields.io/github/v/tag/HardCodeDev777/UnityNeuroSpeech)
![Top lang](https://img.shields.io/github/languages/top/HardCodeDev777/UnityNeuroSpeech)
![quality](https://img.shields.io/badge/quality-best-brightgreen)
![code_style](https://img.shields.io/badge/code_style-goat-lightgrey)

<div align="center">
  <img src="docs/media/logo.png">
</div>

#

> **Make your Unity characters hear, think, and talk â€” using real voice AI. Locally. No cloud.**

---

UnityNeuroSpeech is an open-source framework for creating **fully voice-interactive AI agents** inside Unity.  
It connects:

- ğŸ§  **Whisper** (STT) â€“ converts your speech into text  
- ğŸ’¬ **Ollama** (LLM) â€“ generates smart responses  
- ğŸ—£ï¸ **XTTS** (TTS) â€“ speaks back with *custom voice + emotions*

All locally. All offline.  
No subscriptions, no accounts, no OpenAI API keys.

---

## ğŸš€ What can you build with UnityNeuroSpeech?

- ğŸ® AI characters that understand your voice and reply in real time  
- ğŸ—¿ NPCs with personality and memory  
- ğŸ§ª Experiments in AI conversation and narrative design  
- ğŸ•¹ï¸ Voice-driven gameplay mechanics  
- ğŸ¤– Interactive bots with humanlike voice responses

---

## âœ¨ Core Features

| Feature | Description                                                                                |
|--------|--------------------------------------------------------------------------------------------|
| ğŸ™ï¸ **Voice Input** | Uses [whisper.unity](https://github.com/Macoron/whisper.unity) for accurate speech-to-text |
| ğŸ§  **AI Brain (LLM)** | Easily connect to any local model via [Ollama](https://ollama.com)                         |
| ğŸ—£ï¸ **Custom TTS** | Supports any voice with [Coqui XTTS](https://github.com/idiap/coqui-ai-TTS)                      |
| ğŸ˜„ **Emotions** | Emotion tags (`<happy>`, `<sad>`, etc.) parsed automatically from LLM                      |
| ğŸ¬ **Actions** | Action tags (`<turn_off_lights>`, `<play_cutscene_123>`, etc.) also parsed automatically from LLM                      |
| ğŸ›ï¸ **Agent API** | Subscribe to events like `BeforeTTS()` to monitor your agents                  |
| ğŸ“ **History Saving in JSON** | Save dialog history between player and LLM in JSON with/without AES encryption                 |
| ğŸ› ï¸ **Editor Tools** | Create, manage and customize agents inside Unity Editor easily                                  |
| ğŸ§± **No Cloud** | All models and voice run locally on your machine                                           |
| ğŸŒ **Multilingual** | Works with over **15+ languages**, including English, Russian, Chinese, etc.               |
| ğŸ”Š **Multiple Voices and Languages for Multiple Agents** | Each Agent can have each voice file for any available laguage              |
| âš¡ **High Performance** | Uses **UniTask** instead of Coroutines and Tasks for optimal performance.             |
| ğŸ”§ **Full Build Support** | Full compatibility with both **Mono** and **IL2CPP** scripting backends.           |


---

## ğŸ§ª Built with:

- ğŸ§  [OllamaSharp](https://github.com/awaescher/OllamaSharp) 
- ğŸ¤ [whisper.unity](https://github.com/Macoron/whisper.unity)
- âš¡ [UniTask](https://github.com/Cysharp/UniTask)
- ğŸ§Š [Coqui XTTS](https://github.com/idiap/coqui-ai-TTS)
- ğŸ–¥ï¸ [UV](https://github.com/astral-sh/uv)
- ğŸ¤– Unity 6

---

## âš™ï¸ Compatibility

| Scripting backend | Windows |  Other platforms    |
|-------------------|---------|--------------------|
| Mono              | âœ…       | âŒ (not planned)    |
| IL2CPP            | âœ…       | âŒ (not planned)    |

---

## ğŸ“š Getting Started

See [UnityNeuroSpeech official documentation](https://hardcodedev777.github.io/UnityNeuroSpeech/).

---

## ğŸ˜ Who made this?

UnityNeuroSpeech was created by [HardCodeDev](https://github.com/HardCodeDev777) â€”  solo dev from Russia.

---

## ğŸ—’ï¸ License

UnityNeuroSpeech is licensed under the **MIT License**.
For other Licenses, see [Licenses](LICENSES.md).
